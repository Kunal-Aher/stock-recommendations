{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MySQL Database\n",
      "Database stock_data already exists.\n",
      "Table HINDUNILVR created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['HINDUNILVR']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "symbol data is being fetched for HINDUNILVR\n",
      "No historical data available for the symbol\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['HINDUNILVR']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "live data is being fetched for HINDUNILVR\n",
      "Error fetching live data\n",
      "No live data available for the symbol.  Falling back to historical data.\n",
      "symbol data is being fetched for HINDUNILVR\n",
      "No historical data available either.  Cannot proceed.\n",
      "Empty DataFrame\n",
      "Columns: [id, timestamp, open, high, low, close, volume]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kunal\\AppData\\Local\\Temp\\ipykernel_11492\\1940974252.py:181: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import requests\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from sqlalchemy import create_engine\n",
    "from mysql.connector import Error  # Import Error for exception handling\n",
    "\n",
    "# creating mysql connection\n",
    "def get_mysql_connection():\n",
    "    try:\n",
    "        connection = mysql.connector.connect(\n",
    "            host=\"localhost\",\n",
    "            user=\"root\",\n",
    "            password=\"Aher@123\"\n",
    "        )\n",
    "        if connection.is_connected():\n",
    "            print(\"Connected to MySQL Database\")\n",
    "            return connection\n",
    "    except Error as e:\n",
    "        print(\"Error while connecting to MySQL\", e)\n",
    "        return None\n",
    "\n",
    "def create_database_if_not_exists(cursor, db):\n",
    "    try:\n",
    "        cursor.execute(f\"SHOW DATABASES LIKE '{db}'\")\n",
    "        result = cursor.fetchone()\n",
    "        if not result:\n",
    "            cursor.execute(f\"CREATE DATABASE {db}\")\n",
    "            print(f\"Database {db} created.\")\n",
    "        else:\n",
    "            print(f\"Database {db} already exists.\")\n",
    "    except Error as e:\n",
    "        print(f\"Error creating/checking database: {e}\")\n",
    "\n",
    "# Create table if it doesn't exist\n",
    "def create_table_if_not_exists(cursor, db, symbol):\n",
    "    try:\n",
    "        cursor.execute(f\"USE {db}\")  # Ensure we're using the correct database\n",
    "        cursor.execute(f\"SHOW TABLES LIKE '{symbol}'\")\n",
    "        result = cursor.fetchone()\n",
    "        if not result:\n",
    "            cursor.execute(\n",
    "                f\"\"\"\n",
    "            CREATE TABLE {symbol} (\n",
    "                id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                date DATETIME,\n",
    "                open FLOAT,\n",
    "                high FLOAT,\n",
    "                low FLOAT,\n",
    "                close FLOAT,\n",
    "                volume INT\n",
    "            );\n",
    "            \"\"\"\n",
    "            )\n",
    "            print(f\"Table {symbol} created.\")\n",
    "        else:\n",
    "            print(f\"Table {symbol} already exists.\")\n",
    "    except Error as e:\n",
    "        print(f\"Error creating/checking symbol: {e}\")\n",
    "\n",
    "\n",
    "# fetch historical data\n",
    "def fetch_historical_data(symbol):\n",
    "    try:\n",
    "        if symbol:\n",
    "            histdata = yf.download(symbol)\n",
    "            histdata.reset_index(inplace=True)\n",
    "            histdata.rename(columns={'Date': 'date'}, inplace=True) #rename Date column\n",
    "            print(f\"symbol data is being fetched for {symbol}\")\n",
    "            return histdata\n",
    "        else:\n",
    "            print(\"Symbol is not provided.\")\n",
    "            return None\n",
    "    except Exception as e:  # Using Exception to catch any error from yfinance\n",
    "        print(\"Error fetching historical data\", e)\n",
    "        return None\n",
    "\n",
    "\n",
    "def fetch_livedata(symbol, api_key):\n",
    "    try:\n",
    "        if symbol and api_key:\n",
    "            url = \"https://www.alphavantage.co/query\"\n",
    "            params = {\n",
    "                \"function\": \"TIME_SERIES_DAILY\",\n",
    "                \"symbol\": symbol,\n",
    "                \"apikey\": api_key,\n",
    "                \"outputsize\": \"full\",\n",
    "            }\n",
    "            response = requests.get(url, params=params)\n",
    "            livedata = response.json()\n",
    "            print(f\"live data is being fetched for {symbol}\")\n",
    "\n",
    "            # check for errors\n",
    "            if \"Time Series (Daily)\" not in livedata:\n",
    "                print(\"Error fetching live data\")\n",
    "                return pd.DataFrame()\n",
    "\n",
    "            daily_data = livedata[\"Time Series (Daily)\"]\n",
    "            df = pd.DataFrame.from_dict(daily_data, orient=\"index\")\n",
    "            df.reset_index(inplace=True)\n",
    "            df.columns = [\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "            df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "            df.rename(columns={'Date': 'date', 'Open': 'open', 'High':'high', 'Low':'low', 'Close':'close', 'Volume':'volume'}, inplace=True) # rename columns to match database\n",
    "            df = df.sort_values(by=\"date\", ascending=True)\n",
    "            if 'id' in df.columns:\n",
    "                df.drop(columns=['id'], inplace=True)\n",
    "            return df\n",
    "        else:\n",
    "            print(\"Symbol or API key is not provided.\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(\"Error fetching live data:\", e)\n",
    "        return None\n",
    "\n",
    "\n",
    "def insert_data_insert_into_table(cursor, db, table, data):\n",
    "    if data is None or data.empty:  #\n",
    "        print(\"No data to insert\")\n",
    "        return\n",
    "\n",
    "    encoded_password = \"Aher%40123\"\n",
    "    engine = create_engine(f\"mysql+mysqlconnector://root:{encoded_password}@localhost/{db}\")\n",
    "\n",
    "    try:\n",
    "        df = pd.DataFrame(data)\n",
    "        df.columns = map(str.lower, df.columns) \n",
    "\n",
    "        df.rename(columns={'date': 'date', 'open': 'open', 'high':'high', 'low':'low', 'close':'close', 'volume':'volume'}, inplace=True) # rename columns to match database\n",
    "\n",
    "        \n",
    "        if 'date' in df.columns:\n",
    "            df['date'] = pd.to_datetime(df['date'])  # Convert to datetime\n",
    "\n",
    "        \n",
    "        df.drop_duplicates(subset=['date'], keep='last', inplace=True)\n",
    "        \n",
    "        if 'id' in df.columns:\n",
    "            df = df.drop(columns=['id'])\n",
    "\n",
    "\n",
    "\n",
    "        df.to_sql(name=table, con=engine, if_exists='append', index=False)  # use to_sql\n",
    "\n",
    "        print(f\"{len(df)} rows inserted into {table}.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting data into {table}: {e}\")\n",
    "\n",
    "\n",
    "def run_pipeline(db, symbol, api_key):\n",
    "    # Connect to the database\n",
    "    conn = get_mysql_connection()\n",
    "    if not conn:  \n",
    "        return\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    create_database_if_not_exists(cursor, db)\n",
    "    create_table_if_not_exists(cursor, db, symbol)\n",
    "\n",
    "    historical_data = fetch_historical_data(symbol)\n",
    "    if historical_data is None or historical_data.empty:\n",
    "        print(\"No historical data available for the symbol\")\n",
    "    else:\n",
    "        insert_data_insert_into_table(cursor, db, symbol, historical_data)\n",
    "\n",
    "    livedata = fetch_livedata(symbol, api_key)\n",
    "    if livedata is None or livedata.empty:\n",
    "        print(\"No live data available for the symbol.  Falling back to historical data.\")\n",
    "        historical_data = fetch_historical_data(symbol)\n",
    "        if historical_data is None or historical_data.empty:\n",
    "            print(\"No historical data available either.  Cannot proceed.\")\n",
    "        else:\n",
    "            insert_data_insert_into_table(cursor, db, symbol, historical_data)\n",
    "    else:\n",
    "        insert_data_insert_into_table(cursor, db, symbol, livedata)\n",
    "\n",
    "    conn.commit()\n",
    "\n",
    "    try:\n",
    "        query = f\"SELECT * FROM {db}.{symbol}\"\n",
    "        df = pd.read_sql(query, conn)\n",
    "        print(df.head()) \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the data: {e}\")\n",
    "\n",
    "    finally: \n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "\n",
    "\n",
    "def get_valid_symbol():\n",
    "    while True:\n",
    "        symbol = input(\"Enter the stock symbol (e.g., AAPL): \").upper()\n",
    "        if symbol:  \n",
    "            return symbol\n",
    "        else:\n",
    "            print(\"Invalid symbol. Please enter a valid symbol.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    symbol = get_valid_symbol()\n",
    "    run_pipeline(db=\"stock_data\", symbol=symbol, api_key=\"771O3VPDZ5UH78E3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MySQL Database\n",
      "Database stock_data already exists.\n",
      "Table HINDUNILVR.NS already exists.\n",
      "live data is being fetched for HINDUNILVR.NS\n",
      "Error fetching live data\n",
      "No live data available for the symbol.  Falling back to historical data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "symbol data is being fetched for HINDUNILVR.NS\n",
      "Error inserting data into HINDUNILVR.NS: Index(['date'], dtype='object')\n",
      "Empty DataFrame\n",
      "Columns: [id, timestamp, open, high, low, close, volume]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\kunal\\AppData\\Local\\Temp\\ipykernel_32872\\1313276941.py:241: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import requests\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from sqlalchemy import create_engine\n",
    "from mysql.connector import Error, ProgrammingError # Import Error for exception handling\n",
    "# from yfinance import YFTzMissingError  # Import the specific exception\n",
    "import datetime\n",
    "\n",
    "# creating mysql connection\n",
    "def get_mysql_connection():\n",
    "    try:\n",
    "        connection = mysql.connector.connect(\n",
    "            host=\"localhost\",\n",
    "            user=\"root\",\n",
    "            password=\"Aher@123\"\n",
    "        )\n",
    "        if connection.is_connected():\n",
    "            print(\"Connected to MySQL Database\")\n",
    "            return connection\n",
    "    except Error as e:\n",
    "        print(\"Error while connecting to MySQL\", e)\n",
    "        return None\n",
    "\n",
    "def create_database_if_not_exists(cursor, db):\n",
    "    try:\n",
    "        cursor.execute(f\"SHOW DATABASES LIKE '{db}'\")\n",
    "        result = cursor.fetchone()\n",
    "        if not result:\n",
    "            cursor.execute(f\"CREATE DATABASE {db}\")\n",
    "            print(f\"Database {db} created.\")\n",
    "        else:\n",
    "            print(f\"Database {db} already exists.\")\n",
    "    except Error as e:\n",
    "        print(f\"Error creating/checking database: {e}\")\n",
    "\n",
    "# Create table if it doesn't exist\n",
    "def create_table_if_not_exists(cursor, db, table):\n",
    "    try:\n",
    "        cursor.execute(f\"USE `{db}`\")  # Ensure we're using the correct database; quote the DB name\n",
    "        cursor.execute(f\"SHOW TABLES LIKE '{table}'\")\n",
    "        result = cursor.fetchone()\n",
    "        if not result:\n",
    "            cursor.execute(\n",
    "                f\"\"\"\n",
    "            CREATE TABLE `{table}` (  # quote the table name\n",
    "                id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                date DATETIME,\n",
    "                open FLOAT,\n",
    "                high FLOAT,\n",
    "                low FLOAT,\n",
    "                close FLOAT,\n",
    "                volume INT\n",
    "            );\n",
    "            \"\"\"\n",
    "            )\n",
    "            print(f\"Table {table} created.\")\n",
    "        else:\n",
    "            print(f\"Table {table} already exists.\")\n",
    "    except ProgrammingError as e:\n",
    "        print(f\"Error creating/checking table: {e}\")\n",
    "\n",
    "\n",
    "# fetch historical data\n",
    "def fetch_historical_data(symbol):\n",
    "    try:\n",
    "        if symbol:\n",
    "            histdata = yf.download(symbol)\n",
    "            histdata.reset_index(inplace=True)\n",
    "            histdata.rename(columns={'Date': 'date'}, inplace=True) #rename Date column\n",
    "            print(f\"symbol data is being fetched for {symbol}\")\n",
    "            return histdata\n",
    "        else:\n",
    "            print(\"Symbol is not provided.\")\n",
    "            return None\n",
    "    # except YFTzMissingError as e:  # Catch the specific YFTzMissingError\n",
    "    #     print(f\"YFTzMissingError: Data not found for symbol {symbol}.  Possibly delisted or incorrect symbol.\")\n",
    "    #     return None\n",
    "    except Exception as e:  # Using Exception to catch any other error from yfinance\n",
    "        print(\"Error fetching historical data\", e)\n",
    "        return None\n",
    "\n",
    "\n",
    "def fetch_livedata(symbol, api_key):\n",
    "    try:\n",
    "        if symbol and api_key:\n",
    "            url = \"https://www.alphavantage.co/query\"\n",
    "            params = {\n",
    "                \"function\": \"TIME_SERIES_DAILY\",\n",
    "                \"symbol\": symbol,\n",
    "                \"apikey\": api_key,\n",
    "                \"outputsize\": \"full\",\n",
    "            }\n",
    "            response = requests.get(url, params=params)\n",
    "            livedata = response.json()\n",
    "            print(f\"live data is being fetched for {symbol}\")\n",
    "\n",
    "            # check for errors\n",
    "            if \"Time Series (Daily)\" not in livedata:\n",
    "                print(\"Error fetching live data\")\n",
    "                return pd.DataFrame()\n",
    "\n",
    "            daily_data = livedata[\"Time Series (Daily)\"]\n",
    "            df = pd.DataFrame.from_dict(daily_data, orient=\"index\")\n",
    "            df.reset_index(inplace=True)\n",
    "            df.columns = [\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "            df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "            df.rename(columns={'Date': 'date', 'Open': 'open', 'High':'high', 'Low':'low', 'Close':'close', 'Volume':'volume'}, inplace=True) # rename columns to match database\n",
    "            df = df.sort_values(by=\"date\", ascending=True)\n",
    "            return df\n",
    "        else:\n",
    "            print(\"Symbol or API key is not provided.\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(\"Error fetching live data:\", e)\n",
    "        return pd.DataFrame() # Return an empty dataframe\n",
    "\n",
    "\n",
    "# def insert_data_insert_into_table(cursor, db, table, data):\n",
    "#     if data is None or data.empty:  # check if the dataframe is empty or None\n",
    "#         print(\"No data to insert\")\n",
    "#         return\n",
    "\n",
    "#     encoded_password = \"Aher%40123\"\n",
    "#     engine = create_engine(f\"mysql+mysqlconnector://root:{encoded_password}@localhost/{db}\")\n",
    "\n",
    "#     try:\n",
    "#         # Prepare the dataframe: Convert column names to lowercase, handle date if necessary.\n",
    "#         df = pd.DataFrame(data)\n",
    "#         # Flatten column names and ensure they are all lowercase strings\n",
    "#         df.columns = [\n",
    "#             \" \".join(col).lower() if isinstance(col, tuple) else str(col).lower() for col in df.columns\n",
    "#         ]\n",
    "\n",
    "\n",
    "#         # Standardize column names to match the database table\n",
    "#         df.rename(columns={'date': 'date', 'open': 'open', 'high':'high', 'low':'low', 'close':'close', 'volume':'volume'}, inplace=True) # rename columns to match database\n",
    "\n",
    "#         # Handle date column: Ensure it's in datetime format and named 'date'\n",
    "#         if 'date' in df.columns:\n",
    "#             df['date'] = pd.to_datetime(df['date'])  # Convert to datetime\n",
    "\n",
    "#         # Drop duplicates based on date, before inserting\n",
    "#         df.drop_duplicates(subset=['date'], keep='last', inplace=True)\n",
    "\n",
    "#         #Change data types if needed\n",
    "#         df['open'] = df['open'].astype(float)\n",
    "#         df['high'] = df['high'].astype(float)\n",
    "#         df['low'] = df['low'].astype(float)\n",
    "#         df['close'] = df['close'].astype(float)\n",
    "#         df['volume'] = df['volume'].astype(int)\n",
    "\n",
    "\n",
    "#         # Use SQLAlchemy to insert data. This is the best approach for performance and type handling.\n",
    "#         df.to_sql(name=table, con=engine, if_exists='append', index=False)  # use to_sql\n",
    "\n",
    "#         print(f\"{len(df)} rows inserted into {table}.\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error inserting data into {table}: {e}\")\n",
    "def insert_data_insert_into_table(cursor, db, table, data):\n",
    "    if data is None or data.empty:  # check if the dataframe is empty or None\n",
    "        print(\"No data to insert\")\n",
    "        return\n",
    "\n",
    "    encoded_password = \"Aher%40123\"\n",
    "    engine = create_engine(f\"mysql+mysqlconnector://root:{encoded_password}@localhost/{db}\")\n",
    "\n",
    "    try:\n",
    "        # Prepare the dataframe: Convert column names to lowercase, handle date if necessary.\n",
    "        df = pd.DataFrame(data)\n",
    "        # Flatten column names and ensure they are all lowercase strings\n",
    "        df.columns = [\n",
    "            \" \".join(col).lower() if isinstance(col, tuple) else str(col).lower() for col in df.columns\n",
    "        ]\n",
    "\n",
    "\n",
    "        # Standardize column names to match the database table\n",
    "        df.rename(columns={'date': 'date', 'open': 'open', 'high':'high', 'low':'low', 'close':'close', 'volume':'volume'}, inplace=True) # rename columns to match database\n",
    "\n",
    "        # Handle date column: Ensure it's in datetime format and named 'date'\n",
    "        if 'date' in df.columns:\n",
    "            df['date'] = pd.to_datetime(df['date'])  # Convert to datetime\n",
    "\n",
    "        # Drop duplicates based on date, before inserting\n",
    "        df.drop_duplicates(subset=['date'], keep='last', inplace=True)\n",
    "\n",
    "        # Print column data types before insertion for debugging\n",
    "        print(\"Dataframe before insertion:\", df.dtypes)\n",
    "\n",
    "        #Change data types if needed\n",
    "        try:\n",
    "            df['open'] = df['open'].astype(float)\n",
    "            df['high'] = df['high'].astype(float)\n",
    "            df['low'] = df['low'].astype(float)\n",
    "            df['close'] = df['close'].astype(float)\n",
    "            df['volume'] = df['volume'].astype(int)\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting data types: {e}\")\n",
    "            return\n",
    "\n",
    "        # Use SQLAlchemy to insert data. This is the best approach for performance and type handling.\n",
    "        df.to_sql(name=table, con=engine, if_exists='append', index=False)  # use to_sql\n",
    "\n",
    "        print(f\"{len(df)} rows inserted into {table}.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting data into {table}: {e}\")\n",
    "\n",
    "\n",
    "def run_pipeline(db, symbol, api_key):\n",
    "    # Connect to the database\n",
    "    conn = get_mysql_connection()\n",
    "    if not conn:  # Exit if connection fails\n",
    "        return\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    create_database_if_not_exists(cursor, db)\n",
    "    create_table_if_not_exists(cursor, db, symbol)\n",
    "\n",
    "    livedata = fetch_livedata(symbol, api_key)\n",
    "\n",
    "    if livedata is None or livedata.empty:\n",
    "        print(\"No live data available for the symbol.  Falling back to historical data.\")\n",
    "        historical_data = fetch_historical_data(symbol)\n",
    "        if historical_data is None or historical_data.empty:\n",
    "            print(\"No historical data available either.  Cannot proceed.\")\n",
    "        else:\n",
    "            insert_data_insert_into_table(cursor, db, symbol, historical_data)\n",
    "    else:\n",
    "        insert_data_insert_into_table(cursor, db, symbol, livedata)\n",
    "\n",
    "\n",
    "\n",
    "    conn.commit()\n",
    "\n",
    "    try:\n",
    "        # Quote the table name to handle dots in the symbol\n",
    "        quoted_table = f\"`{symbol}`\"  # Use backticks for quoting identifiers\n",
    "        query = f\"SELECT * FROM `{db}`.{quoted_table}\"  # Correctly quote database and table names.\n",
    "        df = pd.read_sql(query, conn)\n",
    "        print(df.head())  # Show a preview of the data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the data: {e}\")\n",
    "\n",
    "    finally:  # Ensures resources are closed even if errors occur\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "\n",
    "# Input validation\n",
    "def get_valid_symbol():\n",
    "    while True:\n",
    "        symbol = input(\"Enter the stock symbol (e.g., AAPL): \").upper()\n",
    "        if symbol:  # Checks for non-empty input\n",
    "            return symbol\n",
    "        else:\n",
    "            print(\"Invalid symbol. Please enter a valid symbol.\")\n",
    "\n",
    "# Example Usage:\n",
    "if __name__ == \"__main__\":\n",
    "    symbol = get_valid_symbol()\n",
    "    run_pipeline(db=\"stock_data\", symbol=symbol, api_key=\"771O3VPDZ5UH78E3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>HINDUNILVR.NS</th>\n",
       "      <th>HINDUNILVR.NS</th>\n",
       "      <th>HINDUNILVR.NS</th>\n",
       "      <th>HINDUNILVR.NS</th>\n",
       "      <th>HINDUNILVR.NS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1996-01-01</th>\n",
       "      <td>34.524017</td>\n",
       "      <td>34.954136</td>\n",
       "      <td>34.524017</td>\n",
       "      <td>34.744663</td>\n",
       "      <td>11000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-02</th>\n",
       "      <td>34.892696</td>\n",
       "      <td>35.023967</td>\n",
       "      <td>34.535195</td>\n",
       "      <td>34.524023</td>\n",
       "      <td>203500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-03</th>\n",
       "      <td>34.686005</td>\n",
       "      <td>34.828445</td>\n",
       "      <td>34.521218</td>\n",
       "      <td>34.892684</td>\n",
       "      <td>58000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-04</th>\n",
       "      <td>34.688805</td>\n",
       "      <td>34.800524</td>\n",
       "      <td>34.577087</td>\n",
       "      <td>34.632946</td>\n",
       "      <td>111500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-05</th>\n",
       "      <td>34.632935</td>\n",
       "      <td>34.856374</td>\n",
       "      <td>34.353637</td>\n",
       "      <td>34.688793</td>\n",
       "      <td>39500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price              Close          High           Low          Open  \\\n",
       "Ticker     HINDUNILVR.NS HINDUNILVR.NS HINDUNILVR.NS HINDUNILVR.NS   \n",
       "Date                                                                 \n",
       "1996-01-01     34.524017     34.954136     34.524017     34.744663   \n",
       "1996-01-02     34.892696     35.023967     34.535195     34.524023   \n",
       "1996-01-03     34.686005     34.828445     34.521218     34.892684   \n",
       "1996-01-04     34.688805     34.800524     34.577087     34.632946   \n",
       "1996-01-05     34.632935     34.856374     34.353637     34.688793   \n",
       "\n",
       "Price             Volume  \n",
       "Ticker     HINDUNILVR.NS  \n",
       "Date                      \n",
       "1996-01-01         11000  \n",
       "1996-01-02        203500  \n",
       "1996-01-03         58000  \n",
       "1996-01-04        111500  \n",
       "1996-01-05         39500  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=yf.download(\"HINDUNILVR.NS\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stock_front",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
